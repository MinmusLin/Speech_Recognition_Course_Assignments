{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Import Packages and Load Audio\n",
    "\n",
    "In this step, we import the required libraries, such as `librosa` for audio processing, `numpy` for numerical computations, and `matplotlib` for visualization. We load the audio file and inspect its waveform to gain an initial understanding of the speech signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from scipy.fftpack import dct\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the audio signal and sampling rate from the file\n",
    "signal, fs = librosa.load('record.wav', sr=None)\n",
    "\n",
    "#################################################################################\n",
    "#                      Visualization and Data Presentation                      #\n",
    "#################################################################################\n",
    "\n",
    "# Get the duration of the signal in seconds\n",
    "duration = librosa.get_duration(y=signal, sr=fs)\n",
    "\n",
    "# Calculate the number of samples in the signal\n",
    "n_samples = len(signal)\n",
    "\n",
    "# Calculate the max, min, and mean amplitude of the signal\n",
    "max_amplitude = np.max(signal)\n",
    "min_amplitude = np.min(signal)\n",
    "mean_amplitude = np.mean(signal)\n",
    "\n",
    "# Calculate the Root Mean Square (RMS) amplitude, a measure of the signal's power\n",
    "rms_amplitude = librosa.feature.rms(y=signal).mean()\n",
    "\n",
    "# Print the basic information about the audio signal\n",
    "print(f'Sampling Rate: {fs} Hz')\n",
    "print(f'Duration: {duration:.2f} seconds')\n",
    "print(f'Number of Samples: {n_samples}')\n",
    "print(f'Max Amplitude: {max_amplitude:.3f}')\n",
    "print(f'Min Amplitude: {min_amplitude:.3f}')\n",
    "print(f'Mean Amplitude: {mean_amplitude:.3f}')\n",
    "print(f'RMS Amplitude: {rms_amplitude:.3f}')\n",
    "\n",
    "# Plot the waveform of the original audio signal\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.waveshow(signal, sr=fs)\n",
    "plt.ylabel('Amplitude')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.title('Original Signal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Pre-emphasis\n",
    "\n",
    "Pre-emphasis is applied to the signal to amplify higher frequencies, which are typically weaker in speech. This step helps to balance the frequency spectrum, improving the signal-to-noise ratio for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_emphasis(signal, alpha=0.97):\n",
    "    \"\"\"\n",
    "    Apply pre-emphasis to the input audio signal.\n",
    "\n",
    "    Args:\n",
    "        signal (numpy.ndarray): The input audio signal.\n",
    "        alpha (float): Pre-emphasis filter coefficient. Default is 0.97.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The emphasized signal.\n",
    "    \"\"\"\n",
    "    return np.append(signal[0], signal[1:] - alpha * signal[:-1])\n",
    "\n",
    "\n",
    "# Apply pre-emphasis to the original signal\n",
    "emphasized_signal = pre_emphasis(signal)\n",
    "\n",
    "#################################################################################\n",
    "#                      Visualization and Data Presentation                      #\n",
    "#################################################################################\n",
    "\n",
    "# Plot the original and emphasized (pre-emphasis) signals\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot the original signal\n",
    "plt.subplot(2, 1, 1)\n",
    "librosa.display.waveshow(signal, sr=fs)\n",
    "plt.title('Original Signal')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.xlabel('Time (s)')\n",
    "\n",
    "# Plot the emphasized signal after pre-emphasis\n",
    "plt.subplot(2, 1, 2)\n",
    "librosa.display.waveshow(emphasized_signal, sr=fs)\n",
    "plt.title('Emphasized Signal (Pre-emphasis)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the mean and standard deviation of both signals\n",
    "mean_original = np.mean(signal)\n",
    "std_original = np.std(signal)\n",
    "mean_emphasized = np.mean(emphasized_signal)\n",
    "std_emphasized = np.std(emphasized_signal)\n",
    "\n",
    "print(f'Original Signal - Mean: {mean_original:.4f}, Standard Deviation: {std_original:.4f}')\n",
    "print(f'Emphasized Signal - Mean: {mean_emphasized:.4f}, Standard Deviation: {std_emphasized:.4f}')\n",
    "\n",
    "# Compute the FFT of both original and emphasized signals\n",
    "fft_original = np.fft.fft(signal)\n",
    "fft_emphasized = np.fft.fft(emphasized_signal)\n",
    "\n",
    "# Generate the frequency bins for the FFT\n",
    "frequencies = np.fft.fftfreq(len(fft_original), d=1 / fs)\n",
    "\n",
    "# Only take the first half of the frequency spectrum for plotting (positive frequencies)\n",
    "half_n = len(frequencies) // 2\n",
    "\n",
    "# Plot the frequency spectrum of the original and emphasized signals\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot the frequency spectrum of the original signal\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(frequencies[:half_n], np.abs(fft_original[:half_n]))\n",
    "plt.title('Frequency Spectrum of Original Signal')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "# Plot the frequency spectrum of the emphasized signal\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(frequencies[:half_n], np.abs(fft_emphasized[:half_n]))\n",
    "plt.title('Frequency Spectrum of Emphasized Signal')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Windowing\n",
    "\n",
    "In this step, the speech signal is divided into short overlapping frames by applying a window function (e.g., Hamming window). This allows for localized analysis of the signal in both time and frequency domains, necessary for short-term spectral processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def framing(signal, frame_size, frame_stride, fs):\n",
    "    \"\"\"\n",
    "    Frame the signal into overlapping frames and apply a window function (Hamming window).\n",
    "\n",
    "    Args:\n",
    "        signal (numpy.ndarray): The input audio signal.\n",
    "        frame_size (float): Frame size in seconds.\n",
    "        frame_stride (float): Frame stride in seconds.\n",
    "        fs (int): Sampling rate of the signal.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A 2D array where each row is a frame of the signal.\n",
    "    \"\"\"\n",
    "    # Convert frame size and stride from seconds to samples\n",
    "    frame_length, frame_step = frame_size * fs, frame_stride * fs\n",
    "    frame_length = int(round(frame_length))\n",
    "    frame_step = int(round(frame_step))\n",
    "\n",
    "    # Calculate total number of frames and pad the signal if necessary\n",
    "    signal_length = len(signal)\n",
    "    total_frames = int(np.ceil(float(np.abs(signal_length - frame_length) / frame_step)))\n",
    "    padded_signal_length = total_frames * frame_step + frame_length\n",
    "\n",
    "    # Zero-padding the signal to match the required frame length\n",
    "    zeros = np.zeros((padded_signal_length - signal_length))\n",
    "    padded_signal = np.append(signal, zeros)\n",
    "\n",
    "    # Create indices for frames (each row corresponds to a frame)\n",
    "    indices = np.tile(np.arange(0, frame_length), (total_frames, 1)) + np.tile(np.arange(0, total_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "\n",
    "    # Extract frames from the padded signal\n",
    "    frames = padded_signal[indices.astype(np.int32, copy=False)]\n",
    "\n",
    "    # Apply a Hamming window to each frame\n",
    "    window = np.hamming(frame_length)\n",
    "    frames_windowed = frames * window\n",
    "\n",
    "    return frames, frames_windowed, frame_length, total_frames\n",
    "\n",
    "\n",
    "# Define frame size and stride in seconds\n",
    "frame_size = 0.025\n",
    "frame_stride = 0.01\n",
    "\n",
    "# Apply framing and windowing to the emphasized signal\n",
    "frames, frames_windowed, frame_length, total_frames = framing(emphasized_signal, frame_size, frame_stride, fs)\n",
    "\n",
    "#################################################################################\n",
    "#                      Visualization and Data Presentation                      #\n",
    "#################################################################################\n",
    "\n",
    "# Print the total number of frames and frame length\n",
    "print(f'Total number of frames: {total_frames}')\n",
    "print(f'Frame length (in samples): {frame_length}')\n",
    "\n",
    "# Plot a few random frames (both without and with windowing) for comparison\n",
    "plt.figure(figsize=(15, 8))\n",
    "random_frames = random.sample(range(total_frames), 3)\n",
    "for i, frame_idx in enumerate(random_frames):\n",
    "    # Plot frames without windowing\n",
    "    plt.subplot(3, 2, 2 * i + 1)\n",
    "    plt.plot(frames[frame_idx])\n",
    "    plt.title(f'Frame {frame_idx} (Without Window)')\n",
    "    plt.xlabel('Samples')\n",
    "    plt.ylabel('Amplitude')\n",
    "\n",
    "    # Plot frames with Hamming window applied\n",
    "    plt.subplot(3, 2, 2 * i + 2)\n",
    "    plt.plot(frames_windowed[frame_idx])\n",
    "    plt.title(f'Frame {frame_idx} (With Hamming Window)')\n",
    "    plt.xlabel('Samples')\n",
    "    plt.ylabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the first few frames (without and with Hamming window)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Frames without windowing\n",
    "plt.subplot(2, 1, 1)\n",
    "for i in range(3):\n",
    "    plt.plot(frames[i], label=f'Frame {i}')\n",
    "plt.title('Frames without Hamming Window')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "# Frames with Hamming window\n",
    "plt.subplot(2, 1, 2)\n",
    "for i in range(3):\n",
    "    plt.plot(frames_windowed[i], label=f'Frame {i}')\n",
    "plt.title('Frames with Hamming Window')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Short-Time Fourier Transform (STFT)\n",
    "\n",
    "STFT is used to convert the windowed time-domain signal into the frequency domain. Each frame is transformed into its frequency components, producing a spectrogram that represents how frequencies evolve over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft(frames, NFFT):\n",
    "    \"\"\"\n",
    "    Perform Short-Time Fourier Transform on the input frames.\n",
    "\n",
    "    Args:\n",
    "        frames (numpy.ndarray): The input frames, each row is a frame.\n",
    "        NFFT (int): Number of FFT points, determines the frequency resolution.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The magnitude spectrum of each frame.\n",
    "    \"\"\"\n",
    "    # Compute the magnitude of the FFT for each frame\n",
    "    mag_frames = np.abs(np.fft.rfft(frames, NFFT))\n",
    "\n",
    "    # Compute the power spectrum (squared magnitude normalized by the number of FFT points)\n",
    "    pow_frames = ((1.0 / NFFT) * (mag_frames ** 2))\n",
    "\n",
    "    return pow_frames\n",
    "\n",
    "\n",
    "# Set the number of FFT points (frequency resolution)\n",
    "NFFT = 512\n",
    "\n",
    "# Perform STFT on the frames\n",
    "spectrum = stft(frames, NFFT)\n",
    "\n",
    "#################################################################################\n",
    "#                      Visualization and Data Presentation                      #\n",
    "#################################################################################\n",
    "\n",
    "# Plot the spectrum of a few random frames\n",
    "plt.figure(figsize=(15, 10))\n",
    "random_frames = random.sample(range(frames.shape[0]), 3)\n",
    "frequencies = np.linspace(0, fs / 2, NFFT // 2 + 1)\n",
    "for i, frame_idx in enumerate(random_frames):\n",
    "    plt.subplot(3, 1, i + 1)\n",
    "    plt.plot(frequencies, spectrum[frame_idx])\n",
    "    plt.title(f'Spectrum of Frame {frame_idx}')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Magnitude')\n",
    "    plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute and plot the frequency spectrum of the entire emphasized signal\n",
    "fft_full = np.abs(np.fft.rfft(emphasized_signal, NFFT))\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "# Plot the spectrum of the entire signal\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(frequencies, fft_full)\n",
    "plt.title('Frequency Spectrum of the Entire Signal')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.grid()\n",
    "\n",
    "# Plot the spectrum of a randomly selected frame\n",
    "random_frame_idx = random.choice(range(frames.shape[0]))\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(frequencies, spectrum[random_frame_idx])\n",
    "plt.title(f'Frequency Spectrum of Frame {random_frame_idx}')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3D plot of the spectrogram (STFT) in dB scale\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Meshgrid for time (frame index) and frequency\n",
    "time_indices = np.arange(frames.shape[0])\n",
    "freq_indices = np.linspace(0, fs / 2, NFFT // 2 + 1)\n",
    "time_mesh, freq_mesh = np.meshgrid(time_indices, freq_indices)\n",
    "\n",
    "# Convert spectrum to dB scale\n",
    "spectrum_dB = 10 * np.log10(spectrum.T)\n",
    "\n",
    "# Create a 3D surface plot of the spectrogram\n",
    "ax.plot_surface(time_mesh, freq_mesh, spectrum_dB, cmap='viridis', edgecolor='none')\n",
    "ax.set_title('3D Spectrogram (STFT)')\n",
    "ax.set_xlabel('Frame Index')\n",
    "ax.set_ylabel('Frequency (Hz)')\n",
    "ax.set_zlabel('Magnitude (dB)')\n",
    "\n",
    "# Set the viewing angle for better visualization\n",
    "ax.view_init(45, -120)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Mel-filter Bank\n",
    "\n",
    "The Mel-filter bank is applied to the STFT output to approximate human hearing perception. It compresses the frequency scale to focus more on lower frequencies, mimicking how humans perceive sound. This results in the Mel spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_filter_bank(num_filters, NFFT, fs):\n",
    "    \"\"\"\n",
    "    Generate Mel filter banks.\n",
    "\n",
    "    Args:\n",
    "        num_filters (int): The number of Mel filters.\n",
    "        NFFT (int): Number of FFT points, determines frequency resolution.\n",
    "        fs (int): Sampling rate of the signal.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Mel filter banks, shape (num_filters, NFFT // 2 + 1).\n",
    "    \"\"\"\n",
    "    # Convert the low and high frequencies to the Mel scale\n",
    "    low_freq_mel = 0\n",
    "    high_freq_mel = 2595 * np.log10(1 + (fs / 2) / 700)\n",
    "\n",
    "    # Create evenly spaced Mel points\n",
    "    mel_points = np.linspace(low_freq_mel, high_freq_mel, num_filters + 2)\n",
    "\n",
    "    # Convert Mel points back to Hz\n",
    "    hz_points = 700 * (10 ** (mel_points / 2595) - 1)\n",
    "\n",
    "    # Map Hz points to corresponding FFT bin numbers\n",
    "    bin_points = np.floor((NFFT + 1) * hz_points / fs)\n",
    "\n",
    "    # Initialize the filter bank matrix\n",
    "    filters = np.zeros((num_filters, int(np.floor(NFFT / 2 + 1))))\n",
    "\n",
    "    # Create triangular filters between successive Mel points\n",
    "    for m in range(1, num_filters + 1):\n",
    "        f_m_minus = int(bin_points[m - 1])\n",
    "        f_m = int(bin_points[m])\n",
    "        f_m_plus = int(bin_points[m + 1])\n",
    "\n",
    "        # Construct the left side of the triangular filter\n",
    "        for k in range(f_m_minus, f_m):\n",
    "            filters[m - 1, k] = (k - bin_points[m - 1]) / (bin_points[m] - bin_points[m - 1])\n",
    "\n",
    "        # Construct the right side of the triangular filter\n",
    "        for k in range(f_m, f_m_plus):\n",
    "            filters[m - 1, k] = (bin_points[m + 1] - k) / (bin_points[m + 1] - bin_points[m])\n",
    "\n",
    "    return filters\n",
    "\n",
    "# Set the number of Mel filters\n",
    "num_filters = 40\n",
    "\n",
    "# Generate the Mel filter bank and apply it to the spectrum\n",
    "filters = mel_filter_bank(num_filters, NFFT, fs)\n",
    "mel_spectrum = np.dot(spectrum, filters.T)\n",
    "\n",
    "# Replace zero values in the Mel spectrum with a small positive value to avoid log issues\n",
    "mel_spectrum = np.where(mel_spectrum == 0, np.finfo(float).eps, mel_spectrum)\n",
    "\n",
    "#################################################################################\n",
    "#                      Visualization and Data Presentation                      #\n",
    "#################################################################################\n",
    "\n",
    "# Plot the Mel filter bank responses (triangular filters)\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(num_filters):\n",
    "    plt.plot(np.linspace(0, fs / 2, int(NFFT / 2) + 1), filters[i])\n",
    "plt.title('Mel Filter Bank Responses')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 3D plot of the Mel filter bank responses\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create a meshgrid for the Mel filter indices and frequency bins\n",
    "mel_filter_indices = np.arange(filters.shape[0])\n",
    "freq_bins = np.linspace(0, fs / 2, int(NFFT / 2) + 1)\n",
    "filter_mesh, freq_mesh = np.meshgrid(mel_filter_indices, freq_bins)\n",
    "\n",
    "# Plot the 3D surface of Mel filter bank responses\n",
    "filter_responses = filters.T\n",
    "ax.plot_surface(filter_mesh, freq_mesh, filter_responses, cmap='viridis', edgecolor='none')\n",
    "ax.set_title('3D Mel Filter Bank Heatmap')\n",
    "ax.set_xlabel('Mel Filter Index')\n",
    "ax.set_ylabel('Frequency (Hz)')\n",
    "ax.set_zlabel('Amplitude')\n",
    "ax.view_init(45, -120)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3D plot of the Mel spectrogram\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Meshgrid for time (frame index) and Mel filter index\n",
    "time_indices = np.arange(mel_spectrum.shape[0])\n",
    "mel_indices = np.arange(mel_spectrum.shape[1])\n",
    "time_mesh, mel_mesh = np.meshgrid(time_indices, mel_indices)\n",
    "\n",
    "# Convert Mel spectrum to dB scale\n",
    "mel_spectrum_dB = 10 * np.log10(mel_spectrum.T)\n",
    "\n",
    "# Plot the 3D surface of the Mel spectrogram\n",
    "ax.plot_surface(time_mesh, mel_mesh, mel_spectrum_dB, cmap='viridis', edgecolor='none')\n",
    "ax.set_title('3D Mel Spectrogram')\n",
    "ax.set_xlabel('Frame Index')\n",
    "ax.set_ylabel('Mel Filter Index')\n",
    "ax.set_zlabel('Magnitude (dB)')\n",
    "ax.view_init(45, -120)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the Mel spectrum of a few random frames\n",
    "plt.figure(figsize=(15, 10))\n",
    "random_frames = random.sample(range(mel_spectrum.shape[0]), 3)\n",
    "for i, frame_idx in enumerate(random_frames):\n",
    "    plt.subplot(3, 1, i + 1)\n",
    "    plt.plot(mel_spectrum[frame_idx])\n",
    "    plt.title(f'Mel Spectrum of Frame {frame_idx}')\n",
    "    plt.xlabel('Mel Filter Index')\n",
    "    plt.ylabel('Amplitude (dB)')\n",
    "    plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Log Transformation\n",
    "\n",
    "After applying the Mel-filter bank, we take the logarithm of the Mel spectrum to convert the amplitudes to a logarithmic scale, which aligns with how the human ear perceives sound intensity changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_magnitude(x):\n",
    "    \"\"\"\n",
    "    Apply logarithmic compression to the input spectrum to simulate human perception.\n",
    "\n",
    "    Args:\n",
    "        x (numpy.ndarray): The input spectrum (e.g., Mel spectrum).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The logarithmically compressed spectrum.\n",
    "    \"\"\"\n",
    "    # Convert to logarithmic scale (in dB)\n",
    "    return 10 * np.log10(x)\n",
    "\n",
    "# Apply log transformation to the Mel spectrum\n",
    "log_mel_spectrum = log_magnitude(mel_spectrum)\n",
    "\n",
    "#################################################################################\n",
    "#                      Visualization and Data Presentation                      #\n",
    "#################################################################################\n",
    "\n",
    "# 3D plot of the log Mel spectrogram\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create meshgrid for time (frame index) and Mel filter index\n",
    "time_indices = np.arange(log_mel_spectrum.shape[0])\n",
    "mel_indices = np.arange(log_mel_spectrum.shape[1])\n",
    "time_mesh, mel_mesh = np.meshgrid(time_indices, mel_indices)\n",
    "\n",
    "# Transpose the log Mel spectrum for 3D plotting\n",
    "log_mel_spectrum_dB = log_mel_spectrum.T\n",
    "\n",
    "# Plot the 3D surface of the log Mel spectrogram\n",
    "ax.plot_surface(time_mesh, mel_mesh, log_mel_spectrum_dB, cmap='viridis', edgecolor='none')\n",
    "ax.set_title('3D Log Mel Spectrogram')\n",
    "ax.set_xlabel('Frame Index')\n",
    "ax.set_ylabel('Mel Filter Index')\n",
    "ax.set_zlabel('Magnitude (dB)')\n",
    "ax.view_init(45, -120)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the log Mel spectrum for a few random frames\n",
    "plt.figure(figsize=(15, 10))\n",
    "random_frames = random.sample(range(log_mel_spectrum.shape[0]), 3)\n",
    "for i, frame_idx in enumerate(random_frames):\n",
    "    plt.subplot(3, 1, i + 1)\n",
    "    plt.plot(log_mel_spectrum[frame_idx])\n",
    "    plt.title(f'Log Mel Spectrum of Frame {frame_idx}')\n",
    "    plt.xlabel('Mel Filter Index')\n",
    "    plt.ylabel('Magnitude (dB)')\n",
    "    plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Discrete Cosine Transform (DCT)\n",
    "\n",
    "DCT is applied to the log Mel spectrum to obtain the Mel Frequency Cepstral Coefficients (MFCCs). These coefficients represent the most important characteristics of the speech signal and are often used for tasks like speech recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DCT to the log Mel spectrum to compute MFCC features\n",
    "mfcc_features = dct(log_mel_spectrum, type=2, axis=1, norm='ortho')[:, :13]\n",
    "\n",
    "#################################################################################\n",
    "#                      Visualization and Data Presentation                      #\n",
    "#################################################################################\n",
    "\n",
    "# 3D plot of the MFCC features\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create meshgrid for time (frame index) and MFCC coefficient index\n",
    "time_indices = np.arange(mfcc_features.shape[0])\n",
    "mfcc_indices = np.arange(mfcc_features.shape[1])\n",
    "time_mesh, mfcc_mesh = np.meshgrid(time_indices, mfcc_indices)\n",
    "\n",
    "# Transpose the MFCC features for 3D plotting\n",
    "mfcc_features_3d = mfcc_features.T\n",
    "\n",
    "# Plot the 3D surface of the MFCC features\n",
    "ax.plot_surface(time_mesh, mfcc_mesh, mfcc_features_3d, cmap='viridis', edgecolor='none')\n",
    "ax.set_title('3D MFCC Visualization')\n",
    "ax.set_xlabel('Frame Index')\n",
    "ax.set_ylabel('MFCC Coefficient Index')\n",
    "ax.set_zlabel('Magnitude')\n",
    "ax.view_init(45, -120)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the MFCCs for a few random frames\n",
    "random_frames = random.sample(range(mfcc_features.shape[0]), 3)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, frame_idx in enumerate(random_frames):\n",
    "    plt.subplot(3, 1, i + 1)\n",
    "    plt.plot(mfcc_features[frame_idx])\n",
    "    plt.title(f'MFCC of Frame {frame_idx}')\n",
    "    plt.xlabel('MFCC Coefficient Index')\n",
    "    plt.ylabel('Magnitude (dB)')\n",
    "    plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Dynamic Feature Extraction\n",
    "\n",
    "In this step, the first-order (Delta) and second-order (Delta-Delta) derivatives of MFCCs are calculated. These dynamic features capture changes in the speech signal over time, providing additional temporal information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta(feature_matrix, N=2):\n",
    "    \"\"\"\n",
    "    Calculate delta (derivative) of the feature matrix.\n",
    "\n",
    "    Args:\n",
    "        feature_matrix (numpy.ndarray): Input feature matrix (e.g., MFCCs).\n",
    "        N (int): The window size for calculating the delta.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Delta feature matrix.\n",
    "    \"\"\"\n",
    "    # Number of frames in the feature matrix\n",
    "    num_frames, _ = feature_matrix.shape\n",
    "\n",
    "    # Denominator for the delta calculation\n",
    "    denominator = 2 * sum([i ** 2 for i in range(1, N + 1)])\n",
    "\n",
    "    # Initialize the delta feature matrix with the same shape\n",
    "    delta_feature = np.empty_like(feature_matrix)\n",
    "\n",
    "    # Pad the feature matrix at the edges to handle boundary conditions\n",
    "    padded = np.pad(feature_matrix, ((N, N), (0, 0)), mode='edge')\n",
    "\n",
    "    # Compute the delta for each frame\n",
    "    for t in range(num_frames):\n",
    "        delta_feature[t] = np.dot(np.arange(-N, N + 1), padded[t: t + 2 * N + 1]) / denominator\n",
    "\n",
    "    return delta_feature\n",
    "\n",
    "# Compute the first-order delta (Delta) of the MFCC features\n",
    "delta1 = delta(mfcc_features)\n",
    "\n",
    "# Compute the second-order delta (Delta-Delta) of the first-order delta\n",
    "delta2 = delta(delta1)\n",
    "\n",
    "#################################################################################\n",
    "#                      Visualization and Data Presentation                      #\n",
    "#################################################################################\n",
    "\n",
    "# 3D plot of the first-order Delta MFCC features\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create meshgrid for time (frame index) and MFCC coefficient index\n",
    "time_indices = np.arange(delta1.shape[0])\n",
    "mfcc_indices = np.arange(delta1.shape[1])\n",
    "time_mesh, mfcc_mesh = np.meshgrid(time_indices, mfcc_indices)\n",
    "\n",
    "# Transpose the Delta MFCC for 3D plotting\n",
    "delta1_3d = delta1.T\n",
    "\n",
    "# Plot the 3D surface of the Delta MFCC features\n",
    "ax.plot_surface(time_mesh, mfcc_mesh, delta1_3d, cmap='viridis', edgecolor='none')\n",
    "ax.set_title('3D Delta MFCC Visualization')\n",
    "ax.set_xlabel('Frame Index')\n",
    "ax.set_ylabel('MFCC Coefficient Index')\n",
    "ax.set_zlabel('Delta Magnitude')\n",
    "ax.view_init(45, -120)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the Delta MFCCs for a few random frames\n",
    "random_frames = random.sample(range(delta1.shape[0]), 3)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, frame_idx in enumerate(random_frames):\n",
    "    plt.subplot(3, 1, i + 1)\n",
    "    plt.plot(delta1[frame_idx])\n",
    "    plt.title(f'Delta MFCC of Frame {frame_idx}')\n",
    "    plt.xlabel('MFCC Coefficient Index')\n",
    "    plt.ylabel('Delta Magnitude')\n",
    "    plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3D plot of the second-order Delta-Delta MFCC features\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create meshgrid for time (frame index) and MFCC coefficient index\n",
    "time_indices = np.arange(delta2.shape[0])\n",
    "mfcc_indices = np.arange(delta2.shape[1])\n",
    "time_mesh, mfcc_mesh = np.meshgrid(time_indices, mfcc_indices)\n",
    "\n",
    "# Transpose the Delta-Delta MFCC for 3D plotting\n",
    "delta2_3d = delta2.T\n",
    "\n",
    "# Plot the 3D surface of the Delta-Delta MFCC features\n",
    "ax.plot_surface(time_mesh, mfcc_mesh, delta2_3d, cmap='viridis', edgecolor='none')\n",
    "ax.set_title('3D Delta-Delta MFCC Visualization')\n",
    "ax.set_xlabel('Frame Index')\n",
    "ax.set_ylabel('MFCC Coefficient Index')\n",
    "ax.set_zlabel('Delta-Delta Magnitude')\n",
    "ax.view_init(45, -120)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the Delta-Delta MFCCs for a few random frames\n",
    "random_frames = random.sample(range(delta2.shape[0]), 3)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, frame_idx in enumerate(random_frames):\n",
    "    plt.subplot(3, 1, i + 1)\n",
    "    plt.plot(delta2[frame_idx])\n",
    "    plt.title(f'Delta-Delta MFCC of Frame {frame_idx}')\n",
    "    plt.xlabel('MFCC Coefficient Index')\n",
    "    plt.ylabel('Delta-Delta Magnitude')\n",
    "    plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 - Feature Transformation\n",
    "\n",
    "The MFCCs, along with their dynamic features (Delta and Delta-Delta), are normalized to ensure that each feature has a mean of zero and unit variance. This helps to remove biases and scale differences between features, improving model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the MFCC, Delta, and Delta-Delta features horizontally (combine them into one feature set)\n",
    "stacked_features = np.hstack((mfcc_features, delta1, delta2))\n",
    "\n",
    "# Mean normalization: subtract the mean of each feature across all frames\n",
    "cmn_features = stacked_features - np.mean(stacked_features, axis=0)\n",
    "\n",
    "# Variance normalization: divide by the standard deviation of each feature\n",
    "cvn_features = cmn_features / np.std(cmn_features, axis=0)\n",
    "\n",
    "#################################################################################\n",
    "#                      Visualization and Data Presentation                      #\n",
    "#################################################################################\n",
    "\n",
    "# 3D plot of the normalized MFCC, Delta, and Delta-Delta features\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create meshgrid for time (frame index) and feature index (MFCC, Delta, Delta-Delta)\n",
    "time_indices = np.arange(cvn_features.shape[0])\n",
    "feature_indices = np.arange(cvn_features.shape[1])\n",
    "time_mesh, feature_mesh = np.meshgrid(time_indices, feature_indices)\n",
    "\n",
    "# Transpose the normalized features for 3D plotting\n",
    "cvn_features_3d = cvn_features.T\n",
    "\n",
    "# Plot the 3D surface of the normalized MFCC, Delta, and Delta-Delta features\n",
    "ax.plot_surface(time_mesh, feature_mesh, cvn_features_3d, cmap='viridis', edgecolor='none')\n",
    "ax.set_title('3D Normalized MFCC, Delta, Delta-Delta Features')\n",
    "ax.set_xlabel('Frame Index')\n",
    "ax.set_ylabel('Feature Index (MFCC, Delta, Delta-Delta)')\n",
    "ax.set_zlabel('Normalized Feature Value')\n",
    "ax.view_init(45, -120)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the shape of the normalized feature matrix\n",
    "print('CVN Features Shape:', cvn_features.shape)\n",
    "\n",
    "# Print the features of a specific frame (e.g., frame 10)\n",
    "frame_number = 10\n",
    "print(f'Features of Frame {frame_number}:')\n",
    "print('MFCC Features:', mfcc_features[frame_number])\n",
    "print('Delta Features:', delta1[frame_number])\n",
    "print('Delta-Delta Features:', delta2[frame_number])\n",
    "print('Stacked and Normalized Features:', cvn_features[frame_number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 - Principal Component Analysis (PCA)\n",
    "\n",
    "PCA is performed to reduce the dimensionality of the feature set while retaining the most important information. By keeping only the most significant principal components, this step helps to remove redundancy and improve computational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_transformation(features, n_components=12):\n",
    "    \"\"\"\n",
    "    Perform Principal Component Analysis (PCA) on the feature set.\n",
    "\n",
    "    Args:\n",
    "        features (numpy.ndarray): The input features to be transformed.\n",
    "        n_components (int): Number of principal components to keep.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (Transformed features, PCA object)\n",
    "    \"\"\"\n",
    "    # Initialize PCA with the desired number of components\n",
    "    pca = PCA(n_components=n_components)\n",
    "\n",
    "    # Fit the PCA model to the features and transform the data\n",
    "    transformed_features = pca.fit_transform(features)\n",
    "\n",
    "    return transformed_features, pca\n",
    "\n",
    "# Apply PCA to reduce the dimensionality of the stacked features (MFCC, Delta, Delta-Delta)\n",
    "transformed_features, pca_model = feature_transformation(stacked_features)\n",
    "\n",
    "#################################################################################\n",
    "#                      Visualization and Data Presentation                      #\n",
    "#################################################################################\n",
    "\n",
    "# Plot the transformed features for each PCA component\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(transformed_features.shape[1]):\n",
    "    # Plot each PCA component as a heatmap across time frames\n",
    "    plt.subplot(6, 2, i + 1)\n",
    "    plt.imshow(transformed_features[:, i].reshape(-1, 1).T, aspect='auto', cmap='viridis', origin='lower')\n",
    "    plt.colorbar(label='Amplitude', orientation='vertical')\n",
    "    plt.title(f'PCA Component {i + 1}')\n",
    "    plt.xlabel('Frame Index')\n",
    "    plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the explained variance ratio for each PCA component\n",
    "explained_variance = pca_model.explained_variance_ratio_\n",
    "print('Explained variance ratio of each PCA component:')\n",
    "for i, variance in enumerate(explained_variance):\n",
    "    print(f'Component {i + 1}: {variance:.4f}')\n",
    "\n",
    "# Print the PCA component feature vectors\n",
    "print('\\nPCA Component Feature Vectors:')\n",
    "print(pca_model.components_)\n",
    "\n",
    "# Print the transformed features for a specific frame (e.g., frame 10)\n",
    "frame_number = 10\n",
    "print(f'\\nPCA Transformed Features of Frame {frame_number}:')\n",
    "print(transformed_features[frame_number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "xml"
    }
   },
   "source": [
    "# 11 - Comparison with `librosa` MFCC\n",
    "\n",
    "In this step, we compare the custom MFCC implementation with the MFCCs generated by the librosa library to validate our custom implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the hop length based on the frame stride and sampling rate\n",
    "hop_length = int(frame_stride * fs)\n",
    "\n",
    "# Use librosa to compute MFCCs directly from the signal\n",
    "librosa_mfcc = librosa.feature.mfcc(y=signal, sr=fs, n_mfcc=13, n_fft=NFFT, hop_length=hop_length, n_mels=num_filters)\n",
    "\n",
    "# Ensure the custom MFCCs and librosa MFCCs have the same shape by trimming or padding as necessary\n",
    "if librosa_mfcc.shape[1] > mfcc_features.shape[0]:\n",
    "    # Trim the librosa MFCC to match the custom MFCC length\n",
    "    librosa_mfcc = librosa_mfcc[:, :mfcc_features.shape[0]]\n",
    "elif librosa_mfcc.shape[1] < mfcc_features.shape[0]:\n",
    "    # Trim the custom MFCC to match the librosa MFCC length\n",
    "    mfcc_features = mfcc_features[:librosa_mfcc.shape[1], :]\n",
    "\n",
    "#################################################################################\n",
    "#                      Visualization and Data Presentation                      #\n",
    "#################################################################################\n",
    "\n",
    "# Plot the custom MFCC\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(mfcc_features.T, aspect='auto', origin='lower', cmap='viridis', vmin=-600, vmax=100)\n",
    "plt.title('Custom MFCC')\n",
    "plt.colorbar(label='Magnitude (dB)')\n",
    "plt.xlabel('Frame Index')\n",
    "plt.ylabel('MFCC Coefficient Index')\n",
    "\n",
    "# Plot the librosa MFCC\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(librosa_mfcc, aspect='auto', origin='lower', cmap='viridis', vmin=-600, vmax=100)\n",
    "plt.title('Librosa MFCC')\n",
    "plt.colorbar(label='Magnitude (dB)')\n",
    "plt.xlabel('Frame Index')\n",
    "plt.ylabel('MFCC Coefficient Index')\n",
    "\n",
    "# Show the comparison plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mfcc_extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
